{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\n",
    "import tensorflow.keras.backend as K\n",
    "from PIL import Image\n",
    "import os\n",
    "from parse import parse\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/train_images'\n",
    "train_img_paths = [os.path.join(path, d) for d in os.listdir(train_path)]\n",
    "test_path = 'data/test_images'\n",
    "test_img_paths = [os.path.join(path, d) for d in os.listdir(test_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [256, 256]\n",
    "shape = [*size, 3]\n",
    "def load_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(size)\n",
    "    img = np.array(img).astype(np.float32)\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape)\n",
    "densenet = DenseNet121(input_tensor=input_tensor,\n",
    "                    weights='imagenet',\n",
    "                    include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = densenet.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Lambda(lambda x: K.expand_dims(x, axis=-1))(out)\n",
    "out = AveragePooling1D(4)(out)\n",
    "out = Lambda(lambda x: x[:,:,0])(out)\n",
    "\n",
    "model = Model(input_tensor, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 3948)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/train/train.csv')\n",
    "test_df = pd.read_csv('data/test/test.csv')\n",
    "train_ids = train_df['PetID'].tolist()\n",
    "test_ids = test_df['PetID'].tolist()\n",
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Will use only profile images\n",
    "# Predict the features of train and test images\n",
    "def get_profile_img_path(petid, absp):\n",
    "    return os.path.join(absp, '{}-1.jpg'.format(petid))\n",
    "\n",
    "train_features = {}\n",
    "test_features = {}\n",
    "batch_size = 32\n",
    "num_batches = int(np.ceil(len(train_ids) / batch_size))\n",
    "for it in tqdm_notebook(range(num_batches)):\n",
    "    ids = train_ids[it * batch_size: (it + 1) * batch_size]\n",
    "    batch = np.zeros(shape=[batch_size, *shape], dtype=np.float32)\n",
    "    err_inds = []\n",
    "    for i, petid in enumerate(ids):\n",
    "        try:\n",
    "            batch[i] = load_image(get_profile_img_path(petid, train_path))\n",
    "        except:\n",
    "            err_inds.append(i)\n",
    "    f = model.predict(batch)\n",
    "    for i, petid in enumerate(ids):\n",
    "        train_features[petid] = f[i]\n",
    "        \n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = int(np.ceil(len(test_ids) / batch_size))\n",
    "for it in tqdm_notebook(range(num_batches)):\n",
    "    ids = test_ids[it * batch_size: (it + 1) * batch_size]\n",
    "    batch = np.zeros(shape=[batch_size, *shape], dtype=np.float32)\n",
    "    err_inds = []\n",
    "    for i, petid in enumerate(ids):\n",
    "        try:\n",
    "            batch[i] = load_image(get_profile_img_path(petid, test_path))\n",
    "        except:\n",
    "            err_inds.append(i)\n",
    "    f = model.predict(batch)\n",
    "    for i, petid in enumerate(ids):\n",
    "        test_features[petid] = f[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
