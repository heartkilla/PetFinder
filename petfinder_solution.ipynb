{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "# Kaggle [PetFinder.my Adoption Prediction](https://www.kaggle.com/c/petfinder-adoption-prediction) Competition Solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://storage.googleapis.com/kaggle-media/competitions/Petfinder/PetFinder%20-%20Logo.png)\n",
    "![](https://s3.amazonaws.com/cdn-origin-etr.akc.org/wp-content/uploads/2017/11/12232719/Golden-Retriever-On-White-05.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our solution for PetFinder.my Kaggle competition which [me](https://www.kaggle.com/aruchomu) and my teammate [Dmitry Voynov](https://www.kaggle.com/vainof) submitted. <br>\n",
    "The solution scored 0.40767 of [Quadratic Weighted Kappa](https://stats.stackexchange.com/questions/59798/quadratic-weighted-kappa-versus-linear-weighted-kappa?rq=1) (QWK) and reached top 33% on the private leaderboard. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id=\"top\"></a> <br>\n",
    "## Contents\n",
    "1. [Preparations](#1)\n",
    "2. [Feature Extraction from Sentiment and Image Metadata](#2)\n",
    "3. [Text and Image Features](#3)\n",
    "4. [Modeling](#4)\n",
    "5. [Submission](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a> \n",
    "## 1. Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "c96de47d5eff3e66be72395071d692449f6da626"
   },
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "from joblib import Parallel, delayed\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications.densenet import preprocess_input, DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D, \\\n",
    "    MaxPooling1D, Dense, BatchNormalization, Dropout, Embedding, Reshape, Concatenate\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "4ed4b493d39e9531d5d9554ea2ddea4d0e3b6012"
   },
   "outputs": [],
   "source": [
    "# Random seed function (thanks to Benjamin Minixhofer)\n",
    "\n",
    "seed = 73\n",
    "\n",
    "def seed_everything(seed=seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "4fdb1d8b447849e45c4209cda9b773f7c46c0d15"
   },
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "train_df = pd.read_csv('../input/petfinder-adoption-prediction/train/train.csv')\n",
    "test_df = pd.read_csv('../input/petfinder-adoption-prediction/test/test.csv')\n",
    "\n",
    "breeds_df = pd.read_csv('../input/petfinder-adoption-prediction/breed_labels.csv')\n",
    "colors_df = pd.read_csv('../input/petfinder-adoption-prediction/color_labels.csv')\n",
    "states_df = pd.read_csv('../input/petfinder-adoption-prediction/state_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3c321cff4e80e12ca145c37fa2dd37b376b90ae8"
   },
   "outputs": [],
   "source": [
    "# Correct possible data errors\n",
    "\n",
    "# Replace Breed1 with Breed2\n",
    "train_df['Breed1'].replace(0, train_df['Breed2'], inplace=True)\n",
    "\n",
    "# Replace Breed1 with 0\n",
    "ids = ['1bc0f89d8', '15a206d0d', 'f8654865f', '36b20cfb5',\n",
    "       '699a81c51', '85ec1aac0','6a72cfda7'] \n",
    "train_df.loc[train_df['PetID'].isin(ids), 'Breed1'] = 0\n",
    "\n",
    "# Replace Breed2 with 0\n",
    "ids = ['f8654865f', '699a81c51', '6a72cfda7']\n",
    "train_df.loc[train_df['PetID'].isin(ids), 'Breed2'] = 0\n",
    "\n",
    "# Change Type to 1\n",
    "train_df.loc[train_df['PetID'] == '6c399cb06', 'Type'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb85a2bc9042bec614cb9013c0b63c3e2dc2d784"
   },
   "source": [
    "<a id=\"2\"></a> \n",
    "## 2. Feature Extraction from Sentiment and Image Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "0755c99657bc1b9dcff628e915c831212303b792"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 149 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 2199 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 6259 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 11919 tasks      | elapsed:   52.0s\n",
      "[Parallel(n_jobs=-1)]: Done 14993 out of 14993 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 1054 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3972 out of 3972 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 2132 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done 10844 tasks      | elapsed:   25.0s\n",
      "[Parallel(n_jobs=-1)]: Done 14442 out of 14442 | elapsed:   32.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 2396 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3865 out of 3865 | elapsed:    8.4s finished\n"
     ]
    }
   ],
   "source": [
    "# Extraction functions\n",
    "\n",
    "def get_metadata_features(pet_id, dataset):\n",
    "    \"\"\"\n",
    "    Collects the following features from the image metadata for profile images.\n",
    "    \n",
    "    1. Image resolution.\n",
    "    2. Top 3 dominant colors by score.\n",
    "    \"\"\"\n",
    "    json_path = '../input/petfinder-adoption-prediction/{}_metadata/{}-1.json'.format(dataset, pet_id)\n",
    "    image_path = '../input/petfinder-adoption-prediction/{}_images/{}-1.jpg'.format(dataset, pet_id)\n",
    "    \n",
    "    if not os.path.exists(json_path):\n",
    "        # Test sample with no profile picture\n",
    "        if os.path.exists('../input/petfinder-adoption-prediction/{}_metadata/{}-2.json'.format(dataset, pet_id)):\n",
    "            json_path = '../input/petfinder-adoption-prediction/{}_metadata/{}-2.json'.format(dataset, pet_id)\n",
    "            image_path = '../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset, pet_id)\n",
    "        else:\n",
    "            return\n",
    "    \n",
    "    row = {}\n",
    "    \n",
    "    row['PetID'] = pet_id\n",
    "    \n",
    "    with open(json_path) as fp:\n",
    "        row_json = json.load(fp)\n",
    "    \n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        row['img_width'], row['img_height'] = image.size\n",
    "    except:\n",
    "        row['img_width'], row['img_height'] = np.nan, np.nan\n",
    "    \n",
    "    try:\n",
    "        colors = row_json['imagePropertiesAnnotation']['dominantColors']['colors']\n",
    "        reds, greens, blues, scores = [], [], [], []\n",
    "        for color in colors:\n",
    "            reds.append(color['color'].get('red', 0))\n",
    "            greens.append(color['color'].get('green', 0))\n",
    "            blues.append(color['color'].get('blue', 0))\n",
    "            scores.append(color.get('score', 0))\n",
    "        colors_df = pd.DataFrame({'red': reds, 'green': greens, 'blue': blues, 'score': scores})\n",
    "        row.update(dict(zip(['img_color_1_red', 'img_color_1_green', 'img_color_1_blue',\n",
    "                             'img_color_2_red', 'img_color_2_green', 'img_color_2_blue',\n",
    "                             'img_color_3_red', 'img_color_3_green', 'img_color_3_blue'],\n",
    "                            colors_df.sort_values('score', ascending=False).iloc[:3, :-1].values.ravel())))\n",
    "    except:\n",
    "        row.update(dict(zip(['img_color_1_red', 'img_color_1_green', 'img_color_1_blue',\n",
    "                             'img_color_2_red', 'img_color_2_green', 'img_color_2_blue',\n",
    "                             'img_color_3_red', 'img_color_3_green', 'img_color_3_blue'], [np.nan] * 9)))\n",
    "    \n",
    "    return row\n",
    "\n",
    "\n",
    "def get_sentiment_features(filename, dataset):\n",
    "    \"\"\"\n",
    "    Collects the following features from the sentiment data.\n",
    "    \n",
    "    1. Sentences scores mean and variance weighted by magnitude.\n",
    "    2. Document sentiment magnitude and score.\n",
    "    \"\"\"\n",
    "    path = '../input/petfinder-adoption-prediction/' + dataset + '_sentiment'\n",
    "    with open(os.path.join(path, filename)) as fp:\n",
    "        row_json = json.load(fp)\n",
    "    row = {}\n",
    "\n",
    "    row['PetID'] = filename.replace('.json', '')\n",
    "    \n",
    "    try:\n",
    "        magnitudes, scores = [], []\n",
    "        for sentence in row_json['sentences']:\n",
    "            magnitudes.append(sentence['sentiment']['magnitude'])\n",
    "            scores.append(sentence['sentiment']['score'])\n",
    "        sentences_df = pd.DataFrame({'magnitude': magnitudes, 'score': scores})\n",
    "        sentences_df['score'] = sentences_df['magnitude'] * sentences_df['score']\n",
    "        epsilon = np.finfo(np.float32).eps\n",
    "        sentences_df['score'] = sentences_df['magnitude'] / (sentences_df['magnitude'].sum() + epsilon)\n",
    "        row['sentence_score_mean'] = sentences_df['score'].mean()\n",
    "        row['sentence_score_var'] = sentences_df['score'].var()\n",
    "    except:\n",
    "        row['sentence_score_mean'] = np.nan\n",
    "        row['sentence_score_var'] = np.nan \n",
    "\n",
    "    try:\n",
    "        row['document_magnitude'] = row_json['documentSentiment']['magnitude']\n",
    "        row['document_score'] = row_json['documentSentiment']['score']\n",
    "    except:\n",
    "        row['document_magnitude'] = np.nan\n",
    "        row['document_score'] = np.nan\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Use parallel processing\n",
    "train_metadata_rows = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_metadata_features)(pet_id, 'train') for pet_id in train_df['PetID'])\n",
    "train_metadata_df = pd.DataFrame([row for row in train_metadata_rows if row is not None])\n",
    "test_metadata_rows = Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_metadata_features)(pet_id, 'test') for pet_id in test_df['PetID'])\n",
    "test_metadata_df = pd.DataFrame([row for row in test_metadata_rows if row is not None])\n",
    "\n",
    "train_sentiment_df = pd.DataFrame(Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_sentiment_features)(filename,'train') for filename in os.listdir(\n",
    "        '../input/petfinder-adoption-prediction/train_sentiment')))\n",
    "test_sentiment_df = pd.DataFrame(Parallel(n_jobs=-1, verbose=2)(\n",
    "    delayed(get_sentiment_features)(filename, 'test') for filename in os.listdir(\n",
    "        '../input/petfinder-adoption-prediction/test_sentiment')))\n",
    "\n",
    "# Merge everything\n",
    "train_merged = pd.merge(train_df, train_metadata_df, how='left', on='PetID')\n",
    "train_merged = pd.merge(train_merged, train_sentiment_df, how='left', on='PetID')\n",
    "test_merged = pd.merge(test_df, test_metadata_df, how='left', on='PetID')\n",
    "test_merged = pd.merge(test_merged, test_sentiment_df, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "882a946ee7b72fb1951346b59277af2d992be1c0"
   },
   "outputs": [],
   "source": [
    "# New features\n",
    "\n",
    "# Add name length\n",
    "train_merged['name_len'] = train_merged['Name'].map(len, na_action='ignore')\n",
    "test_merged['name_len'] = test_merged['Name'].map(len, na_action='ignore')\n",
    "\n",
    "# Add description length\n",
    "train_merged['desc_len'] = train_merged['Description'].map(len, na_action='ignore')\n",
    "test_merged['desc_len'] = test_merged['Description'].map(len, na_action='ignore')\n",
    "\n",
    "# Add RescuerID count\n",
    "train_merged['rescuer_count'] = train_merged['RescuerID'].replace(train_merged.groupby('RescuerID').size())\n",
    "test_merged['rescuer_count'] = test_merged['RescuerID'].replace(test_merged.groupby('RescuerID').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a> \n",
    "## 3. Text and Image Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "edc9c88fed42fcf74b039f15f605758516094822"
   },
   "source": [
    "### 3.1. Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "4515255ce17a21a21f06cc23bb33193f25bf4d7a"
   },
   "outputs": [],
   "source": [
    "# We simply average pretrained FastText vectors for description\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec')\n",
    "\n",
    "pet_ids = train_df[~train_df['Description'].isna()]['PetID']\n",
    "vects = []\n",
    "found_pet_ids = []\n",
    "for pet_id in pet_ids:\n",
    "    desc = train_df[train_df['PetID'] == pet_id]['Description'].values[0].split(' ')\n",
    "    word_vectors = []\n",
    "    for word in desc:\n",
    "        try:\n",
    "            word_vectors.append(model.get_vector(word))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if word_vectors:\n",
    "        mean_vect = np.mean(word_vectors, axis=0)\n",
    "        vects.append(mean_vect)\n",
    "        found_pet_ids.append(pet_id)\n",
    "fasttext_train_df = pd.DataFrame(np.array(vects)).add_prefix('fasttext_')\n",
    "fasttext_train_df['PetID'] = found_pet_ids\n",
    "train_merged = pd.merge(train_merged, fasttext_train_df, how='left', on='PetID')\n",
    "\n",
    "pet_ids = test_df[~test_df['Description'].isna()]['PetID']\n",
    "vects = []\n",
    "found_pet_ids = []\n",
    "for pet_id in pet_ids:\n",
    "    desc = test_df[test_df['PetID'] == pet_id]['Description'].values[0].split(' ')\n",
    "    word_vectors = []\n",
    "    for word in desc:\n",
    "        try:\n",
    "            word_vectors.append(model.get_vector(word))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    if word_vectors:\n",
    "        mean_vect = np.mean(word_vectors, axis=0)\n",
    "        vects.append(mean_vect)\n",
    "        found_pet_ids.append(pet_id)\n",
    "fasttext_test_df = pd.DataFrame(np.array(vects)).add_prefix('fasttext_')\n",
    "fasttext_test_df['PetID'] = found_pet_ids\n",
    "test_merged = pd.merge(test_merged, fasttext_test_df, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3e04a93d7b124a3c8f8531f6b3b2344cc544bcfe"
   },
   "outputs": [],
   "source": [
    "text_columns = ['Description']\n",
    "\n",
    "# Fill nans with empty text\n",
    "train_merged[text_columns] = train_merged[text_columns].fillna('')\n",
    "test_merged[text_columns] = test_merged[text_columns].fillna('')\n",
    "\n",
    "# Text feature extractor class\n",
    "# We use TF-IDF vectorizer and then extract SVD and NMF vectors with 13 components each\n",
    "\n",
    "class TextFeatureExtractor():\n",
    "    \"\"\"Extracts text features from text columns.\"\"\"\n",
    "    def __init__(self, n_components):\n",
    "        self.tfidf = TfidfVectorizer(min_df=2, max_features=None,\n",
    "                          strip_accents='unicode', analyzer='word', token_pattern='\\w+',\n",
    "                          ngram_range=(1, 3), use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "        self.svd = TruncatedSVD(n_components=n_components, random_state=seed)\n",
    "        self.nmf = NMF(n_components=n_components, random_state=seed)\n",
    "        \n",
    "    def fit_transform(self, X_text):\n",
    "        text_features = []\n",
    "        for col in X_text.columns:\n",
    "            tfidf_col = self.tfidf.fit_transform(X_text[col])\n",
    "            \n",
    "            svd_col = self.svd.fit_transform(tfidf_col)\n",
    "            svd_col = pd.DataFrame(svd_col)\n",
    "            svd_col = svd_col.add_prefix('SVD_{}_'.format(col))\n",
    "            text_features.append(svd_col)\n",
    "            \n",
    "            nmf_col = self.nmf.fit_transform(tfidf_col)\n",
    "            nmf_col = pd.DataFrame(nmf_col)\n",
    "            nmf_col = nmf_col.add_prefix('NMF_{}_'.format(col))\n",
    "            text_features.append(nmf_col)\n",
    "            \n",
    "        text_features = pd.concat(text_features, axis=1)\n",
    "        \n",
    "        return text_features\n",
    "    \n",
    "    def transform(self, X_text):\n",
    "        text_features = []\n",
    "        for col in X_text.columns:\n",
    "            tfidf_col = self.tfidf.transform(X_text[col])\n",
    "            \n",
    "            svd_col = self.svd.transform(tfidf_col)\n",
    "            svd_col = pd.DataFrame(svd_col)\n",
    "            svd_col = svd_col.add_prefix('SVD_{}_'.format(col))\n",
    "            text_features.append(svd_col)\n",
    "            \n",
    "            nmf_col = self.nmf.transform(tfidf_col)\n",
    "            nmf_col = pd.DataFrame(nmf_col)\n",
    "            nmf_col = nmf_col.add_prefix('NMF_{}_'.format(col))\n",
    "            text_features.append(nmf_col)\n",
    "            \n",
    "        text_features = pd.concat(text_features, axis=1)\n",
    "        \n",
    "        return text_features\n",
    "\n",
    "    \n",
    "text_feature_extractor = TextFeatureExtractor(n_components=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28ea1a7f8c4cb7cbb2137be64f10a20bb1df679a"
   },
   "source": [
    " ### 3.2 Image Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "6f9f66e8a47769c3230dd62c6bc2cb63ee1b8e7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 916/916 [02:31<00:00,  4.77it/s]\n",
      "100%|██████████| 242/242 [00:34<00:00,  6.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# We extract image features using DenseNet121 and apply Average Pooling\n",
    "# with window_size=4 for profile images and window_size=8 for second images.\n",
    "\n",
    "weights_path = '../input/densenet121weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "class ImageFeatureExtractor():\n",
    "    def __init__(self,\n",
    "                 shape=[256, 256, 3],\n",
    "                 average_pooling_window=4):\n",
    "        self.shape = shape\n",
    "        self.size = self.shape[:2]\n",
    "        input_tensor = Input(shape)\n",
    "        densenet = DenseNet121(input_tensor=input_tensor,\n",
    "                               weights=weights_path,\n",
    "                               include_top=False)\n",
    "        out = densenet.output\n",
    "        out = GlobalAveragePooling2D()(out)\n",
    "        out = Lambda(lambda x: K.expand_dims(x, axis=-1))(out)\n",
    "        if average_pooling_window:\n",
    "            out = AveragePooling1D(average_pooling_window)(out)\n",
    "        out = Lambda(lambda x: x[:,:,0])(out)\n",
    "        \n",
    "        self.model = Model(input_tensor, out)\n",
    "        self.feats_shape = list(map(int, self.model.output.shape[1:]))\n",
    "\n",
    "    def resize_to_square(self, img):\n",
    "        return img.resize(self.size) \n",
    "\n",
    "    def resize_saving_ratio(self, img):\n",
    "        # works if self.size represents a square\n",
    "        # resize initial image\n",
    "        max_dim = max(img.width, img.height)\n",
    "        k = self.size[0] / max_dim\n",
    "        width = int(img.width * k)\n",
    "        height = int(img.height * k)\n",
    "        img = img.resize([width, height])\n",
    "        # concat with black rectangle\n",
    "        res_img = Image.new('RGB', self.size)\n",
    "        res_img.paste(img, (0, 0))\n",
    "        return res_img\n",
    "\n",
    "    def load_image_by_path(self, filepath, resize_method='square'):\n",
    "        img = Image.open(filepath)\n",
    "        if resize_method == 'square':\n",
    "            img = self.resize_to_square(img)\n",
    "        else:\n",
    "            img = self.resize_saving_ratio(img)\n",
    "        img = np.array(img).astype(np.float32)\n",
    "        img = preprocess_input(img)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.repeat(np.expand_dims(img, axis=2), repeats=3, axis=2)\n",
    "        return img\n",
    "\n",
    "    def extract(self, filepath, resize_method='square'):\n",
    "        img = self.load_image_by_path(filepath, resize_method='square')\n",
    "        return self.model.predict(np.expand_dims(img, axis=0))\n",
    "\n",
    "    def extract_all(self, filepaths, batch_size=16, resize_method='square'):\n",
    "        res_feats = np.empty(shape=[0]+self.feats_shape, dtype=np.float32)\n",
    "        num_batches = int(np.ceil(len(filepaths) / batch_size))\n",
    "        for it in tqdm(range(num_batches)):\n",
    "            batch_filepaths = filepaths[it * batch_size: (it + 1) * batch_size]\n",
    "            batch = []\n",
    "            for fp in batch_filepaths:\n",
    "                img = self.load_image_by_path(fp, resize_method=resize_method)\n",
    "                batch.append(img)\n",
    "            batch = np.array(batch)\n",
    "            feats = self.model.predict(batch)\n",
    "            res_feats = np.append(res_feats, feats, axis=0)\n",
    "        return res_feats\n",
    "\n",
    "\n",
    "def get_image_filepaths(pet_ids, dataset, img_number):\n",
    "    filepaths = []\n",
    "    found_pet_ids = []\n",
    "    for pet_id in pet_ids:\n",
    "        path = '../input/petfinder-adoption-prediction/{}_images/{}-{}.jpg'.format(dataset,\n",
    "                                                                                   pet_id,\n",
    "                                                                                   img_number)\n",
    "        if os.path.exists(path):\n",
    "            filepaths.append(path)\n",
    "            found_pet_ids.append(pet_id)\n",
    "        elif os.path.exists('../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset, pet_id)):\n",
    "            path = '../input/petfinder-adoption-prediction/{}_images/{}-2.jpg'.format(dataset,\n",
    "                                                                                      pet_id)\n",
    "            filepaths.append(path)\n",
    "            found_pet_ids.append(pet_id)\n",
    "    return filepaths, found_pet_ids\n",
    "\n",
    "# Profile images\n",
    "image_feature_extractor = ImageFeatureExtractor()\n",
    "\n",
    "train_img_filepaths, train_found_pet_ids = get_image_filepaths(train_df['PetID'], 'train', 1)\n",
    "test_img_filepaths, test_found_pet_ids = get_image_filepaths(test_df['PetID'], 'test', 1)\n",
    "\n",
    "train_img_feats = image_feature_extractor.extract_all(train_img_filepaths,\n",
    "                                                      resize_method='square')\n",
    "train_img_feats_df = pd.DataFrame(train_img_feats).add_prefix('img_feat_')\n",
    "train_img_feats_df['PetID'] = train_found_pet_ids\n",
    "test_img_feats = image_feature_extractor.extract_all(test_img_filepaths,\n",
    "                                                     resize_method='square')\n",
    "test_img_feats_df = pd.DataFrame(test_img_feats).add_prefix('img_feat_')\n",
    "test_img_feats_df['PetID'] = test_found_pet_ids\n",
    "    \n",
    "train_merged = pd.merge(train_merged, train_img_feats_df, how='left', on='PetID')\n",
    "test_merged = pd.merge(test_merged, test_img_feats_df, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "8b5aa6b3648f0d16d9fd6b6189d18df79662b2c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 724/724 [02:11<00:00,  4.42it/s]\n",
      "100%|██████████| 183/183 [00:31<00:00,  4.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Second images\n",
    "image_feature_extractor = ImageFeatureExtractor(average_pooling_window=8)\n",
    "\n",
    "train_img_filepaths, train_found_pet_ids = get_image_filepaths(train_df['PetID'], 'train', 2)\n",
    "test_img_filepaths, test_found_pet_ids = get_image_filepaths(test_df['PetID'], 'test', 2)\n",
    "\n",
    "train_img_feats = image_feature_extractor.extract_all(train_img_filepaths,\n",
    "                                                      resize_method='square')\n",
    "train_img_feats_df = pd.DataFrame(train_img_feats).add_prefix('img2_feat_')\n",
    "train_img_feats_df['PetID'] = train_found_pet_ids\n",
    "test_img_feats = image_feature_extractor.extract_all(test_img_filepaths,\n",
    "                                                     resize_method='square')\n",
    "test_img_feats_df = pd.DataFrame(test_img_feats).add_prefix('img2_feat_')\n",
    "test_img_feats_df['PetID'] = test_found_pet_ids\n",
    "    \n",
    "train_merged = pd.merge(train_merged, train_img_feats_df, how='left', on='PetID')\n",
    "test_merged = pd.merge(test_merged, test_img_feats_df, how='left', on='PetID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92306b593c87bc8bf9657c1509082cbce0fbd96f"
   },
   "source": [
    "<a id=\"4\"></a> \n",
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "919d40b68e5c86b3c362ecdf8d85a7d527fd7c54"
   },
   "source": [
    "### 4.1. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "8f72c061680000f0bd7207b353c122a05f2c437f"
   },
   "outputs": [],
   "source": [
    "# Regression objective\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Competition metric\n",
    "def qwk(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3d1d454bdd1536514c7e099019252e57f3472db"
   },
   "source": [
    "### 4.2. Thresholds Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "db578b97008e3f93929ee3f142b2b51a4354a35d"
   },
   "outputs": [],
   "source": [
    "# We tried different rounding techniques for threshold optimization.\n",
    "# For us rounding by following train distribution gave best results.\n",
    "\n",
    "def get_thresholds_from_dist(y_true, y_pred):\n",
    "    \"\"\"Calculates thresholds for raw predictions\n",
    "    so as to follow the true distribution.\n",
    "    \"\"\"\n",
    "    idxs = np.cumsum(np.bincount(y_true))[:-1]\n",
    "    idxs = (idxs * y_pred.size / y_true.size).astype(int)\n",
    "    return np.sort(y_pred)[idxs]\n",
    "\n",
    "def allocate_to_rate(y_pred, thresholds):\n",
    "    \"\"\"Allocates raw predictions to adoption rates.\"\"\"\n",
    "    rates = np.zeros(y_pred.size, dtype=int)\n",
    "    for i in range(4):\n",
    "        rates[y_pred >= thresholds[i]] = i + 1\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cba9505fd71c636de1ec369a4592deb213f5cdb"
   },
   "source": [
    "### 4.3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Neural Net Embeddings\n",
    "We trained a neural net with embeddings for some categorical features. <br>\n",
    "We then used the embeddings to train the LightGBM model. <br>\n",
    "This part was mainly done by my teammate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "0efe5a42f28bed15ef2dfadcae74e44e9b5b34c7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Final datasets arrangement\n",
    "\n",
    "X_train = train_merged.drop(columns=['PetID', 'AdoptionSpeed'])\n",
    "y_train = train_merged['AdoptionSpeed']\n",
    "\n",
    "X_test = test_merged.drop(columns=['PetID'])\n",
    "\n",
    "# We also add the most frequent breed of each rescuer as feature.\n",
    "X_train['rescuer_breed_mode'] = X_train['RescuerID'].map(X_train.groupby('RescuerID')['Breed1'].agg(\n",
    "    lambda x:x.value_counts().index[0]))\n",
    "X_test['rescuer_breed_mode'] = X_test['RescuerID'].map(X_test.groupby('RescuerID')['Breed1'].agg(\n",
    "    lambda x:x.value_counts().index[0]))\n",
    "\n",
    "cat_feats = ['Type', 'Breed1', 'Breed2', 'Vaccinated',\n",
    "             'Dewormed', 'Sterilized', 'State', 'rescuer_breed_mode']\n",
    "\n",
    "X_train = X_train.drop(columns=['Name', 'RescuerID', 'Description'])\n",
    "X_test = X_test.drop(columns=['Name', 'RescuerID', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful dicts\n",
    "\n",
    "onehot_feats = ['Type', 'Gender',\n",
    "             'Color1', 'Color2', 'Color3', 'Vaccinated',\n",
    "             'Dewormed', 'Sterilized']\n",
    "onehot_sizes = dict(X_train[onehot_feats].nunique())\n",
    "onehot_sizes['Color2'] = onehot_sizes['Color1']\n",
    "onehot_sizes['Color3'] = onehot_sizes['Color1']\n",
    "cat_feats = ['Breed1', 'Breed2', 'rescuer_breed_mode', 'State']\n",
    "X_concat = pd.concat([X_train, X_test])\n",
    "embedding_sizes = {\n",
    "    'Breed1': 32,\n",
    "    'Breed2': 32,\n",
    "    'rescuer_breed_mode': 32,\n",
    "    'State': 8\n",
    "}\n",
    "cat_feats_sizes = {\n",
    "    'Breed1': X_concat['Breed1'].nunique(),\n",
    "    'Breed2': X_concat['Breed2'].nunique(),\n",
    "    'rescuer_breed_mode': X_concat['rescuer_breed_mode'].nunique(),\n",
    "    'State': X_concat['State'].nunique()\n",
    "}\n",
    "\n",
    "cat_feats_mappings = {}\n",
    "for cat_feat in cat_feats:\n",
    "    mapping = {}\n",
    "    vals = X_concat[cat_feat].unique()\n",
    "    vals.sort()\n",
    "    for i, feat in enumerate(vals):\n",
    "        mapping[feat] = i\n",
    "    cat_feats_mappings[cat_feat] = mapping\n",
    "\n",
    "img_feats = ['img_feat_{}'.format(i) for i in range(256)]\n",
    "text_feats = ['fasttext_{}'.format(i) for i in range(300)]\n",
    "numerical_feats = [col for col in X_train.columns \n",
    "                   if not col in img_feats and\n",
    "                   not col in text_feats and\n",
    "                   not col in onehot_feats and\n",
    "                   not col in cat_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical feats\n",
    "num_scaler = StandardScaler()\n",
    "X_train[numerical_feats] = num_scaler.fit_transform(X_train[numerical_feats])\n",
    "X_test[numerical_feats] = num_scaler.transform(X_test[numerical_feats])\n",
    "\n",
    "# Image feats\n",
    "img_scaler = StandardScaler()\n",
    "X_train[img_feats] = img_scaler.fit_transform(X_train[img_feats])\n",
    "X_test[img_feats] = img_scaler.transform(X_test[img_feats])\n",
    "\n",
    "# Text feats\n",
    "text_scaler = StandardScaler()\n",
    "X_train[text_feats] = text_scaler.fit_transform(X_train[text_feats])\n",
    "X_test[text_feats] = text_scaler.transform(X_test[text_feats])\n",
    "\n",
    "X_train[X_train.isna()] = 0\n",
    "X_test[X_test.isna()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    K.clear_session()\n",
    "    # Numerical feats\n",
    "    num_input = Input(shape=[len(numerical_feats)])\n",
    "\n",
    "    num_out = Dense(32, activation='relu')(num_input)\n",
    "    num_out = BatchNormalization()(num_out)\n",
    "    num_out = Dropout(rate=0.66)(num_out)\n",
    "\n",
    "    # Image feats\n",
    "    img_input = Input(shape=[256])\n",
    "\n",
    "    img_out = Lambda(lambda x: K.expand_dims(x, axis=-1))(img_input)\n",
    "    img_out = AveragePooling1D(4)(img_out)\n",
    "    img_out = Lambda(lambda x: x[:,:,0])(img_out)\n",
    "    img_out = Dense(128, activation='relu')(img_out)\n",
    "    img_out = BatchNormalization()(img_out)\n",
    "    img_out = Dropout(rate=0.66)(img_out)\n",
    "\n",
    "    # Text feats\n",
    "    text_input = Input(shape=[300])\n",
    "\n",
    "    text_out = Dense(128, activation='relu')(text_input)\n",
    "    text_out = BatchNormalization()(text_out)\n",
    "    text_out = Dropout(rate=0.66)(text_out)\n",
    "\n",
    "    # Categorical feats\n",
    "    cat_inputs = []\n",
    "    cat_outs = []\n",
    "    for cat_feat in cat_feats:\n",
    "        cat_input = Input(shape=[1])\n",
    "\n",
    "        cat_out = Embedding(input_dim=cat_feats_sizes[cat_feat],\n",
    "                            output_dim=embedding_sizes[cat_feat],\n",
    "                            input_length=1)(cat_input)\n",
    "        cat_out = Reshape(target_shape=[embedding_sizes[cat_feat]])(cat_out)\n",
    "        cat_out = Dense(embedding_sizes[cat_feat], activation='relu')(cat_out)\n",
    "        cat_out = BatchNormalization()(cat_out)\n",
    "        cat_out = Dropout(rate=0.66)(cat_out)\n",
    "\n",
    "        cat_inputs.append(cat_input)\n",
    "        cat_outs.append(cat_out)\n",
    "\n",
    "    feat_inputs = []\n",
    "    feat_outs = []\n",
    "    for onehot_feat in onehot_feats:\n",
    "        feat_input = Input(shape=[onehot_sizes[onehot_feat]])\n",
    "\n",
    "        feat_out = Dense(8, activation='relu')(feat_input)\n",
    "        feat_out = BatchNormalization()(feat_out)\n",
    "        feat_out = Dropout(rate=0.66)(feat_out)\n",
    "\n",
    "        feat_inputs.append(feat_input)\n",
    "        feat_outs.append(feat_out)\n",
    "\n",
    "    cat_outs += feat_outs\n",
    "    cats_out = Concatenate()(cat_outs)\n",
    "    cats_out = Dense(64, activation='relu')(cats_out)\n",
    "    cats_out = BatchNormalization()(cats_out)\n",
    "    cats_out = Dropout(rate=0.66)(cats_out)\n",
    "\n",
    "    # Concatenate dense outputs from different features\n",
    "    out = Concatenate()([num_out, img_out, text_out, cats_out])\n",
    "    out = Dense(192, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(rate=0.66)(out)\n",
    "    out = Dense(64, activation='relu')(out)\n",
    "    out = BatchNormalization()(out)\n",
    "    out = Dropout(rate=0.66)(out)\n",
    "    out = Dense(1)(out)\n",
    "\n",
    "    inputs = [num_input] + [img_input] + [text_input] + cat_inputs + feat_inputs\n",
    "    outputs = [out]\n",
    "    model = Model(inputs=inputs,\n",
    "                  outputs=outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data\n",
    "train_num_data = X_train[numerical_feats].values\n",
    "train_img_data = X_train[img_feats].values\n",
    "train_text_data = X_train[text_feats].values\n",
    "train_cat_data = X_train[cat_feats].values.T\n",
    "\n",
    "train_onh_data = []\n",
    "# Mapping onehot categories to vectors\n",
    "for onh in onehot_feats:\n",
    "    vals = X_train[onh].values\n",
    "    vals = to_categorical(np.clip(vals - 1, 0, np.inf).astype(np.uint8), num_classes=onehot_sizes[onh])\n",
    "    train_onh_data.append(vals)\n",
    "\n",
    "# Mapping cat_feats using cat_feats_mappings\n",
    "for i, cat_feat in enumerate(cat_feats):\n",
    "    train_feats = train_cat_data[i]\n",
    "    for j in range(len(train_feats)):\n",
    "        train_feats[j] = cat_feats_mappings[cat_feat][train_feats[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to list of 15 arrays\n",
    "train_data = \\\n",
    "[train_num_data] + \\\n",
    "[train_img_data] + \\\n",
    "[train_text_data] + \\\n",
    "[d for d in train_cat_data] + \\\n",
    "train_onh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming data\n",
    "test_num_data = X_test[numerical_feats].values\n",
    "test_img_data = X_test[img_feats].values\n",
    "test_text_data = X_test[text_feats].values\n",
    "test_cat_data = X_test[cat_feats].values.T\n",
    "\n",
    "# categories range should start from 0\n",
    "\n",
    "test_onh_data = []\n",
    "# Mapping onehot categories to vectors\n",
    "for onh in onehot_feats:\n",
    "    vals = X_test[onh].values\n",
    "    vals = to_categorical(np.clip(vals - 1, 0, np.inf).astype(np.uint8), num_classes=onehot_sizes[onh])\n",
    "    test_onh_data.append(vals)\n",
    "\n",
    "# Mapping cat_feats using cat_feats_mappings\n",
    "for i, cat_feat in enumerate(cat_feats):\n",
    "    test_feats = test_cat_data[i]\n",
    "    for j in range(len(test_feats)):\n",
    "        test_feats[j] = cat_feats_mappings[cat_feat][test_feats[j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to list of 15 arrays\n",
    "test_data = \\\n",
    "[test_num_data] + \\\n",
    "[test_img_data] + \\\n",
    "[test_text_data] + \\\n",
    "[d for d in test_cat_data] + \\\n",
    "test_onh_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_loss(y_true, y_pred):\n",
    "    diff = y_true - y_pred\n",
    "    return K.sqrt(K.mean(K.square(diff)))\n",
    "\n",
    "def map_to_int(y_true, y_pred, preds):\n",
    "    thresholds = get_thresholds_from_dist(y_true, y_pred)\n",
    "    return allocate_to_rate(preds, thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Fold 0 ----\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 11994 samples, validate on 2999 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "11994/11994 [==============================] - 13s 1ms/sample - loss: 2.2381 - val_loss: 1.2966\n",
      "Epoch 2/100\n",
      "11994/11994 [==============================] - 8s 654us/sample - loss: 1.4388 - val_loss: 1.2199\n",
      "Epoch 3/100\n",
      "11994/11994 [==============================] - 8s 659us/sample - loss: 1.3212 - val_loss: 1.2180\n",
      "Epoch 4/100\n",
      "11994/11994 [==============================] - 8s 660us/sample - loss: 1.2689 - val_loss: 1.1841\n",
      "Epoch 5/100\n",
      "11994/11994 [==============================] - 8s 663us/sample - loss: 1.2285 - val_loss: 1.1757\n",
      "Epoch 6/100\n",
      "11994/11994 [==============================] - 8s 653us/sample - loss: 1.1985 - val_loss: 1.1673\n",
      "Epoch 7/100\n",
      "11994/11994 [==============================] - 8s 686us/sample - loss: 1.1786 - val_loss: 1.1646\n",
      "Epoch 8/100\n",
      "11994/11994 [==============================] - 9s 710us/sample - loss: 1.1674 - val_loss: 1.1796\n",
      "Epoch 9/100\n",
      "11994/11994 [==============================] - 8s 701us/sample - loss: 1.1639 - val_loss: 1.1606\n",
      "Epoch 10/100\n",
      "11994/11994 [==============================] - 9s 727us/sample - loss: 1.1659 - val_loss: 1.1623\n",
      "Epoch 11/100\n",
      "11994/11994 [==============================] - 8s 664us/sample - loss: 1.1542 - val_loss: 1.1781\n",
      "Epoch 12/100\n",
      "11994/11994 [==============================] - 8s 660us/sample - loss: 1.1413 - val_loss: 1.1610\n",
      "Epoch 13/100\n",
      "11994/11994 [==============================] - 8s 658us/sample - loss: 1.1486 - val_loss: 1.1744\n",
      "Epoch 14/100\n",
      "11994/11994 [==============================] - 9s 713us/sample - loss: 1.1311 - val_loss: 1.1726\n",
      "TR___RMSE: 1.01909___QWK: 0.51964\n",
      "VAL___RMSE: 1.07731___QWK: 0.36042\n",
      "---- Fold 1 ----\n",
      "Train on 11994 samples, validate on 2999 samples\n",
      "Epoch 1/100\n",
      "11994/11994 [==============================] - 13s 1ms/sample - loss: 2.2240 - val_loss: 1.3337\n",
      "Epoch 2/100\n",
      "11994/11994 [==============================] - 9s 712us/sample - loss: 1.4126 - val_loss: 1.2593\n",
      "Epoch 3/100\n",
      "11994/11994 [==============================] - 8s 656us/sample - loss: 1.3263 - val_loss: 1.1895\n",
      "Epoch 4/100\n",
      "11994/11994 [==============================] - 8s 658us/sample - loss: 1.2751 - val_loss: 1.2345\n",
      "Epoch 5/100\n",
      "11994/11994 [==============================] - 8s 671us/sample - loss: 1.2360 - val_loss: 1.1836\n",
      "Epoch 6/100\n",
      "11994/11994 [==============================] - 8s 665us/sample - loss: 1.2045 - val_loss: 1.1696\n",
      "Epoch 7/100\n",
      "11994/11994 [==============================] - 8s 660us/sample - loss: 1.1810 - val_loss: 1.1522\n",
      "Epoch 8/100\n",
      "11994/11994 [==============================] - 8s 660us/sample - loss: 1.1678 - val_loss: 1.1674\n",
      "Epoch 9/100\n",
      "11994/11994 [==============================] - 8s 658us/sample - loss: 1.1648 - val_loss: 1.1599\n",
      "Epoch 10/100\n",
      "11994/11994 [==============================] - 8s 664us/sample - loss: 1.1627 - val_loss: 1.1591\n",
      "Epoch 11/100\n",
      "11994/11994 [==============================] - 8s 690us/sample - loss: 1.1493 - val_loss: 1.1757\n",
      "Epoch 12/100\n",
      "11994/11994 [==============================] - 9s 761us/sample - loss: 1.1396 - val_loss: 1.1795\n",
      "TR___RMSE: 1.02436___QWK: 0.48312\n",
      "VAL___RMSE: 1.07343___QWK: 0.40456\n",
      "---- Fold 2 ----\n",
      "Train on 11994 samples, validate on 2999 samples\n",
      "Epoch 1/100\n",
      "11994/11994 [==============================] - 12s 1ms/sample - loss: 2.2231 - val_loss: 1.2813\n",
      "Epoch 2/100\n",
      "11994/11994 [==============================] - 8s 656us/sample - loss: 1.4097 - val_loss: 1.2172\n",
      "Epoch 3/100\n",
      "11994/11994 [==============================] - 8s 658us/sample - loss: 1.3305 - val_loss: 1.1807\n",
      "Epoch 4/100\n",
      "11994/11994 [==============================] - 8s 668us/sample - loss: 1.2695 - val_loss: 1.1856\n",
      "Epoch 5/100\n",
      "11994/11994 [==============================] - 8s 667us/sample - loss: 1.2244 - val_loss: 1.1688\n",
      "Epoch 6/100\n",
      "11994/11994 [==============================] - 8s 666us/sample - loss: 1.1977 - val_loss: 1.1749\n",
      "Epoch 7/100\n",
      "11994/11994 [==============================] - 8s 692us/sample - loss: 1.1836 - val_loss: 1.1677\n",
      "Epoch 8/100\n",
      "11994/11994 [==============================] - 9s 711us/sample - loss: 1.1627 - val_loss: 1.1664\n",
      "Epoch 9/100\n",
      "11994/11994 [==============================] - 8s 662us/sample - loss: 1.1609 - val_loss: 1.1697\n",
      "Epoch 10/100\n",
      "11994/11994 [==============================] - 8s 668us/sample - loss: 1.1552 - val_loss: 1.1634\n",
      "Epoch 11/100\n",
      "11994/11994 [==============================] - 8s 669us/sample - loss: 1.1495 - val_loss: 1.1622\n",
      "Epoch 12/100\n",
      "11994/11994 [==============================] - 8s 666us/sample - loss: 1.1528 - val_loss: 1.1745\n",
      "Epoch 13/100\n",
      "11994/11994 [==============================] - 8s 664us/sample - loss: 1.1434 - val_loss: 1.1696\n",
      "Epoch 14/100\n",
      "11994/11994 [==============================] - 8s 666us/sample - loss: 1.1280 - val_loss: 1.1925\n",
      "Epoch 15/100\n",
      "11994/11994 [==============================] - 8s 670us/sample - loss: 1.1362 - val_loss: 1.1729\n",
      "Epoch 16/100\n",
      "11994/11994 [==============================] - 9s 717us/sample - loss: 1.1245 - val_loss: 1.1686\n",
      "TR___RMSE: 1.01614___QWK: 0.51387\n",
      "VAL___RMSE: 1.07806___QWK: 0.35706\n",
      "---- Fold 3 ----\n",
      "Train on 11995 samples, validate on 2998 samples\n",
      "Epoch 1/100\n",
      "11995/11995 [==============================] - 15s 1ms/sample - loss: 2.2977 - val_loss: 1.3316\n",
      "Epoch 2/100\n",
      "11995/11995 [==============================] - 8s 668us/sample - loss: 1.4131 - val_loss: 1.2449\n",
      "Epoch 3/100\n",
      "11995/11995 [==============================] - 8s 664us/sample - loss: 1.3223 - val_loss: 1.2172\n",
      "Epoch 4/100\n",
      "11995/11995 [==============================] - 8s 668us/sample - loss: 1.2742 - val_loss: 1.2349\n",
      "Epoch 5/100\n",
      "11995/11995 [==============================] - 9s 715us/sample - loss: 1.2268 - val_loss: 1.2433\n",
      "Epoch 6/100\n",
      "11995/11995 [==============================] - 8s 674us/sample - loss: 1.1946 - val_loss: 1.1829\n",
      "Epoch 7/100\n",
      "11995/11995 [==============================] - 8s 672us/sample - loss: 1.1814 - val_loss: 1.1848\n",
      "Epoch 8/100\n",
      "11995/11995 [==============================] - 8s 674us/sample - loss: 1.1751 - val_loss: 1.1659\n",
      "Epoch 9/100\n",
      "11995/11995 [==============================] - 9s 711us/sample - loss: 1.1522 - val_loss: 1.1642\n",
      "Epoch 10/100\n",
      "11995/11995 [==============================] - 9s 712us/sample - loss: 1.1502 - val_loss: 1.1720\n",
      "Epoch 11/100\n",
      "11995/11995 [==============================] - 8s 669us/sample - loss: 1.1534 - val_loss: 1.1712\n",
      "Epoch 12/100\n",
      "11995/11995 [==============================] - 8s 670us/sample - loss: 1.1369 - val_loss: 1.1687\n",
      "Epoch 13/100\n",
      "11995/11995 [==============================] - 8s 673us/sample - loss: 1.1277 - val_loss: 1.1744\n",
      "Epoch 14/100\n",
      "11995/11995 [==============================] - 9s 720us/sample - loss: 1.1244 - val_loss: 1.2277\n",
      "TR___RMSE: 1.02177___QWK: 0.49572\n",
      "VAL___RMSE: 1.07899___QWK: 0.39290\n",
      "---- Fold 4 ----\n",
      "Train on 11995 samples, validate on 2998 samples\n",
      "Epoch 1/100\n",
      "11995/11995 [==============================] - 12s 1ms/sample - loss: 2.2950 - val_loss: 1.3662\n",
      "Epoch 2/100\n",
      "11995/11995 [==============================] - 8s 662us/sample - loss: 1.4251 - val_loss: 1.2875\n",
      "Epoch 3/100\n",
      "11995/11995 [==============================] - 8s 694us/sample - loss: 1.3315 - val_loss: 1.2516\n",
      "Epoch 4/100\n",
      "11995/11995 [==============================] - 8s 709us/sample - loss: 1.2663 - val_loss: 1.2255\n",
      "Epoch 5/100\n",
      "11995/11995 [==============================] - 8s 668us/sample - loss: 1.2232 - val_loss: 1.2317\n",
      "Epoch 6/100\n",
      "11995/11995 [==============================] - 8s 668us/sample - loss: 1.1991 - val_loss: 1.2135\n",
      "Epoch 7/100\n",
      "11995/11995 [==============================] - 8s 672us/sample - loss: 1.1647 - val_loss: 1.2260\n",
      "Epoch 8/100\n",
      "11995/11995 [==============================] - 8s 668us/sample - loss: 1.1528 - val_loss: 1.2316\n",
      "Epoch 9/100\n",
      "11995/11995 [==============================] - 8s 667us/sample - loss: 1.1584 - val_loss: 1.2236\n",
      "Epoch 10/100\n",
      "11995/11995 [==============================] - 8s 666us/sample - loss: 1.1406 - val_loss: 1.2284\n",
      "Epoch 11/100\n",
      "11995/11995 [==============================] - 9s 727us/sample - loss: 1.1393 - val_loss: 1.2209\n",
      "TR___RMSE: 1.02954___QWK: 0.47463\n",
      "VAL___RMSE: 1.10159___QWK: 0.36884\n",
      "QWK CV: 0.37675589705374773 +/- 0.01871241569185031\n",
      "RMSE CV: 1.0818764086134633 +/- 0.010038876863883831\n"
     ]
    }
   ],
   "source": [
    "# CV\n",
    "seed_everything()\n",
    "\n",
    "n_splits = 5\n",
    "early_stopping_steps = 5\n",
    "epochs = 100\n",
    "\n",
    "X_train = train_data\n",
    "X_test = test_data\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               min_delta=1e-4,\n",
    "                               patience=early_stopping_steps,\n",
    "                               restore_best_weights=True)\n",
    "callbacks = [early_stopping]\n",
    "\n",
    "gr_kfold_split = GroupKFold(n_splits=n_splits).split([0] * len(train_df),\n",
    "                                              y_train,\n",
    "                                              groups=train_df['RescuerID'])\n",
    "\n",
    "oof_train = np.zeros(shape=[len(train_df)])\n",
    "oof_test = np.zeros(shape=[len(test_df), n_splits])\n",
    "\n",
    "qwks = []\n",
    "rmses = []\n",
    "\n",
    "embeddingses = {}\n",
    "for cat_feat in cat_feats:\n",
    "    embeddingses[cat_feat] = []\n",
    "    \n",
    "for i, (train_inds, test_inds) in enumerate(gr_kfold_split):\n",
    "    print('---- Fold {} ----'.format(i))\n",
    "\n",
    "    X_tr = []\n",
    "    X_val = []\n",
    "    for X_inp in X_train:\n",
    "        X_tr.append(X_inp[train_inds])\n",
    "        X_val.append(X_inp[test_inds])\n",
    "        \n",
    "    y_tr = np.array(y_train)[train_inds]\n",
    "    y_val = np.array(y_train)[test_inds]\n",
    "          \n",
    "    model = get_model()\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "                  loss='mse')\n",
    "    \n",
    "    model.fit(X_tr, y_tr,\n",
    "              batch_size=32,\n",
    "              validation_data=(X_val, y_val),\n",
    "              epochs=epochs,\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    embedding_layers = [l for l in model.layers if isinstance(l, Embedding)]\n",
    "    for cat_feat, emb_layer in zip(cat_feats, embedding_layers):\n",
    "        embeddingses[cat_feat].append(emb_layer.get_weights()[0])\n",
    "    \n",
    "    tr_pred = model.predict(X_tr)\n",
    "    val_pred = model.predict(X_val)\n",
    "    \n",
    "    tr_pred = np.squeeze(tr_pred)\n",
    "    val_pred = np.squeeze(val_pred)\n",
    "    \n",
    "    tr_rates = map_to_int(y_tr, tr_pred, tr_pred)\n",
    "    val_rates = map_to_int(y_tr, tr_pred, val_pred)\n",
    "    \n",
    "    tr_rmse = rmse(y_tr, tr_pred)\n",
    "    tr_qwk = qwk(y_tr, tr_rates)\n",
    "    \n",
    "    print('TR___RMSE: {:7.5F}___QWK: {:7.5F}'.format(tr_rmse, tr_qwk))\n",
    "    \n",
    "    val_rmse = rmse(y_val, val_pred)\n",
    "    val_qwk = qwk(y_val, val_rates)\n",
    "    \n",
    "    print('VAL___RMSE: {:7.5F}___QWK: {:7.5F}'.format(val_rmse, val_qwk))\n",
    "    \n",
    "# Out-of-fold predictions\n",
    "    oof_train[test_inds] = val_pred\n",
    "    oof_test_pred = model.predict(X_test)\n",
    "    oof_test_pred = np.squeeze(oof_test_pred)\n",
    "    oof_test[:, i] = oof_test_pred\n",
    "    \n",
    "    qwks.append(val_qwk)\n",
    "    rmses.append(val_rmse)\n",
    "    \n",
    "print('QWK CV: {} +/- {}'.format(np.mean(qwks), np.std(qwks)))\n",
    "print('RMSE CV: {} +/- {}'.format(np.mean(rmses), np.std(rmses)))\n",
    "\n",
    "for cat_feat in cat_feats:\n",
    "    embeddingses[cat_feat] = np.mean(np.array(embeddingses[cat_feat]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 LightGBM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final datasets arrangement\n",
    "\n",
    "X_train = train_merged.drop(columns=['PetID', 'AdoptionSpeed'])\n",
    "y_train = train_merged['AdoptionSpeed']\n",
    "\n",
    "X_test = test_merged.drop(columns=['PetID'])\n",
    "\n",
    "# The most frequent breed of each rescuer as feature.\n",
    "X_train['rescuer_breed_mode'] = X_train['RescuerID'].map(X_train.groupby('RescuerID')['Breed1'].agg(\n",
    "    lambda x:x.value_counts().index[0]))\n",
    "X_test['rescuer_breed_mode'] = X_test['RescuerID'].map(X_test.groupby('RescuerID')['Breed1'].agg(\n",
    "    lambda x:x.value_counts().index[0]))\n",
    "\n",
    "cat_feats = ['Type', 'Vaccinated',\n",
    "             'Dewormed', 'Sterilized'] \n",
    "\n",
    "X_train = X_train.drop(columns=['Name', 'RescuerID'])\n",
    "X_test = X_test.drop(columns=['Name', 'RescuerID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the embeddings and inserting them into the dataframes\n",
    "\n",
    "breeds = pd.concat([X_train['Breed1'], X_test['Breed1']]).unique()\n",
    "embed_list = []\n",
    "for breed in breeds:\n",
    "    embed_list.append(embeddingses['Breed1'][cat_feats_mappings['Breed1'][breed]])\n",
    "embed_list = np.array(embed_list)\n",
    "breed1_embed_df = pd.DataFrame(embed_list).add_prefix('breed1_embed_')\n",
    "breed1_embed_df['Breed1'] = breeds\n",
    "X_train = X_train.merge(breed1_embed_df, how='left', on='Breed1')\n",
    "X_test = X_test.merge(breed1_embed_df, how='left', on='Breed1')\n",
    "\n",
    "breeds = pd.concat([X_train['Breed2'], X_test['Breed2']]).unique()\n",
    "embed_list = []\n",
    "for breed in breeds:\n",
    "    embed_list.append(embeddingses['Breed2'][cat_feats_mappings['Breed2'][breed]])\n",
    "embed_list = np.array(embed_list)\n",
    "breed1_embed_df = pd.DataFrame(embed_list).add_prefix('breed2_embed_')\n",
    "breed1_embed_df['Breed2'] = breeds\n",
    "X_train = X_train.merge(breed1_embed_df, how='left', on='Breed2')\n",
    "X_test = X_test.merge(breed1_embed_df, how='left', on='Breed2')\n",
    "\n",
    "breeds = pd.concat([X_train['rescuer_breed_mode'], X_test['rescuer_breed_mode']]).unique()\n",
    "embed_list = []\n",
    "for breed in breeds:\n",
    "    embed_list.append(embeddingses['rescuer_breed_mode'][cat_feats_mappings['rescuer_breed_mode'][breed]])\n",
    "embed_list = np.array(embed_list)\n",
    "breed1_embed_df = pd.DataFrame(embed_list).add_prefix('rescuer_breed_mode_embed_')\n",
    "breed1_embed_df['rescuer_breed_mode'] = breeds\n",
    "X_train = X_train.merge(breed1_embed_df, how='left', on='rescuer_breed_mode')\n",
    "X_test = X_test.merge(breed1_embed_df, how='left', on='rescuer_breed_mode')\n",
    "\n",
    "breeds = pd.concat([X_train['State'], X_test['State']]).unique()\n",
    "embed_list = []\n",
    "for breed in breeds:\n",
    "    embed_list.append(embeddingses['State'][cat_feats_mappings['State'][breed]])\n",
    "embed_list = np.array(embed_list)\n",
    "breed1_embed_df = pd.DataFrame(embed_list).add_prefix('state_embed_')\n",
    "breed1_embed_df['State'] = breeds\n",
    "X_train = X_train.merge(breed1_embed_df, how='left', on='State')\n",
    "X_test = X_test.merge(breed1_embed_df, how='left', on='State')\n",
    "\n",
    "X_train = X_train.drop(columns=['Breed1', 'Breed2', 'State', 'rescuer_breed_mode'])\n",
    "X_test = X_test.drop(columns=['Breed1', 'Breed2', 'State', 'rescuer_breed_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 1.10141\tvalid_1's rmse: 1.09383\n",
      "[200]\ttraining's rmse: 1.06191\tvalid_1's rmse: 1.06861\n",
      "[300]\ttraining's rmse: 1.03461\tvalid_1's rmse: 1.05377\n",
      "[400]\ttraining's rmse: 1.01402\tvalid_1's rmse: 1.04438\n",
      "[500]\ttraining's rmse: 0.997284\tvalid_1's rmse: 1.03885\n",
      "[600]\ttraining's rmse: 0.982431\tvalid_1's rmse: 1.03474\n",
      "[700]\ttraining's rmse: 0.969258\tvalid_1's rmse: 1.03161\n",
      "[800]\ttraining's rmse: 0.956835\tvalid_1's rmse: 1.02992\n",
      "[900]\ttraining's rmse: 0.945343\tvalid_1's rmse: 1.02814\n",
      "[1000]\ttraining's rmse: 0.934452\tvalid_1's rmse: 1.02731\n",
      "[1100]\ttraining's rmse: 0.924119\tvalid_1's rmse: 1.02656\n",
      "[1200]\ttraining's rmse: 0.914088\tvalid_1's rmse: 1.02571\n",
      "[1300]\ttraining's rmse: 0.904211\tvalid_1's rmse: 1.02538\n",
      "[1400]\ttraining's rmse: 0.894588\tvalid_1's rmse: 1.02497\n",
      "[1500]\ttraining's rmse: 0.885205\tvalid_1's rmse: 1.02442\n",
      "[1600]\ttraining's rmse: 0.876385\tvalid_1's rmse: 1.02421\n",
      "[1700]\ttraining's rmse: 0.867779\tvalid_1's rmse: 1.02386\n",
      "[1800]\ttraining's rmse: 0.859226\tvalid_1's rmse: 1.0234\n",
      "[1900]\ttraining's rmse: 0.850656\tvalid_1's rmse: 1.02347\n",
      "[2000]\ttraining's rmse: 0.842563\tvalid_1's rmse: 1.02373\n",
      "[2100]\ttraining's rmse: 0.834294\tvalid_1's rmse: 1.02356\n",
      "[2200]\ttraining's rmse: 0.826349\tvalid_1's rmse: 1.02345\n",
      "[2300]\ttraining's rmse: 0.818526\tvalid_1's rmse: 1.0234\n",
      "[2400]\ttraining's rmse: 0.810916\tvalid_1's rmse: 1.02341\n",
      "[2500]\ttraining's rmse: 0.80326\tvalid_1's rmse: 1.0236\n",
      "[2600]\ttraining's rmse: 0.795831\tvalid_1's rmse: 1.02363\n",
      "[2700]\ttraining's rmse: 0.7885\tvalid_1's rmse: 1.02346\n",
      "[2800]\ttraining's rmse: 0.781361\tvalid_1's rmse: 1.02365\n",
      "Early stopping, best iteration is:\n",
      "[2387]\ttraining's rmse: 0.811934\tvalid_1's rmse: 1.02325\n",
      "QWK: 0.43792644197581865, RMSE: 1.0232518129730621\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 1.09633\tvalid_1's rmse: 1.11525\n",
      "[200]\ttraining's rmse: 1.05686\tvalid_1's rmse: 1.08692\n",
      "[300]\ttraining's rmse: 1.02979\tvalid_1's rmse: 1.07212\n",
      "[400]\ttraining's rmse: 1.00947\tvalid_1's rmse: 1.06455\n",
      "[500]\ttraining's rmse: 0.992628\tvalid_1's rmse: 1.06002\n",
      "[600]\ttraining's rmse: 0.977944\tvalid_1's rmse: 1.05668\n",
      "[700]\ttraining's rmse: 0.964771\tvalid_1's rmse: 1.05357\n",
      "[800]\ttraining's rmse: 0.952379\tvalid_1's rmse: 1.05174\n",
      "[900]\ttraining's rmse: 0.940527\tvalid_1's rmse: 1.05048\n",
      "[1000]\ttraining's rmse: 0.929631\tvalid_1's rmse: 1.04946\n",
      "[1100]\ttraining's rmse: 0.919193\tvalid_1's rmse: 1.04864\n",
      "[1200]\ttraining's rmse: 0.908918\tvalid_1's rmse: 1.04808\n",
      "[1300]\ttraining's rmse: 0.899231\tvalid_1's rmse: 1.04769\n",
      "[1400]\ttraining's rmse: 0.88968\tvalid_1's rmse: 1.04661\n",
      "[1500]\ttraining's rmse: 0.880371\tvalid_1's rmse: 1.04579\n",
      "[1600]\ttraining's rmse: 0.871384\tvalid_1's rmse: 1.04579\n",
      "[1700]\ttraining's rmse: 0.862548\tvalid_1's rmse: 1.04531\n",
      "[1800]\ttraining's rmse: 0.854017\tvalid_1's rmse: 1.04538\n",
      "[1900]\ttraining's rmse: 0.8457\tvalid_1's rmse: 1.04458\n",
      "[2000]\ttraining's rmse: 0.837288\tvalid_1's rmse: 1.04449\n",
      "[2100]\ttraining's rmse: 0.829178\tvalid_1's rmse: 1.04445\n",
      "[2200]\ttraining's rmse: 0.8213\tvalid_1's rmse: 1.04453\n",
      "[2300]\ttraining's rmse: 0.813483\tvalid_1's rmse: 1.04433\n",
      "[2400]\ttraining's rmse: 0.805908\tvalid_1's rmse: 1.04448\n",
      "[2500]\ttraining's rmse: 0.798304\tvalid_1's rmse: 1.04448\n",
      "[2600]\ttraining's rmse: 0.791063\tvalid_1's rmse: 1.04453\n",
      "[2700]\ttraining's rmse: 0.783936\tvalid_1's rmse: 1.04487\n",
      "[2800]\ttraining's rmse: 0.777118\tvalid_1's rmse: 1.04432\n",
      "Early stopping, best iteration is:\n",
      "[2304]\ttraining's rmse: 0.813151\tvalid_1's rmse: 1.04425\n",
      "QWK: 0.4653409015103467, RMSE: 1.0442501784816183\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 1.1003\tvalid_1's rmse: 1.09928\n",
      "[200]\ttraining's rmse: 1.05971\tvalid_1's rmse: 1.07435\n",
      "[300]\ttraining's rmse: 1.03131\tvalid_1's rmse: 1.06143\n",
      "[400]\ttraining's rmse: 1.01048\tvalid_1's rmse: 1.05411\n",
      "[500]\ttraining's rmse: 0.993853\tvalid_1's rmse: 1.04944\n",
      "[600]\ttraining's rmse: 0.978748\tvalid_1's rmse: 1.04566\n",
      "[700]\ttraining's rmse: 0.965254\tvalid_1's rmse: 1.04301\n",
      "[800]\ttraining's rmse: 0.952873\tvalid_1's rmse: 1.04144\n",
      "[900]\ttraining's rmse: 0.941118\tvalid_1's rmse: 1.04011\n",
      "[1000]\ttraining's rmse: 0.930208\tvalid_1's rmse: 1.03879\n",
      "[1100]\ttraining's rmse: 0.919681\tvalid_1's rmse: 1.03774\n",
      "[1200]\ttraining's rmse: 0.909545\tvalid_1's rmse: 1.03683\n",
      "[1300]\ttraining's rmse: 0.899552\tvalid_1's rmse: 1.03631\n",
      "[1400]\ttraining's rmse: 0.890349\tvalid_1's rmse: 1.03597\n",
      "[1500]\ttraining's rmse: 0.88125\tvalid_1's rmse: 1.0354\n",
      "[1600]\ttraining's rmse: 0.8723\tvalid_1's rmse: 1.03437\n",
      "[1700]\ttraining's rmse: 0.863692\tvalid_1's rmse: 1.0343\n",
      "[1800]\ttraining's rmse: 0.855156\tvalid_1's rmse: 1.03387\n",
      "[1900]\ttraining's rmse: 0.84673\tvalid_1's rmse: 1.03435\n",
      "[2000]\ttraining's rmse: 0.838481\tvalid_1's rmse: 1.03421\n",
      "[2100]\ttraining's rmse: 0.830598\tvalid_1's rmse: 1.03408\n",
      "[2200]\ttraining's rmse: 0.822772\tvalid_1's rmse: 1.03428\n",
      "[2300]\ttraining's rmse: 0.814915\tvalid_1's rmse: 1.03438\n",
      "Early stopping, best iteration is:\n",
      "[1802]\ttraining's rmse: 0.854995\tvalid_1's rmse: 1.03383\n",
      "QWK: 0.4278081717387383, RMSE: 1.0338252534710735\n",
      "\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 1.09685\tvalid_1's rmse: 1.11908\n",
      "[200]\ttraining's rmse: 1.05781\tvalid_1's rmse: 1.09001\n",
      "[300]\ttraining's rmse: 1.03086\tvalid_1's rmse: 1.07347\n",
      "[400]\ttraining's rmse: 1.01048\tvalid_1's rmse: 1.0635\n",
      "[500]\ttraining's rmse: 0.993962\tvalid_1's rmse: 1.05816\n",
      "[600]\ttraining's rmse: 0.979016\tvalid_1's rmse: 1.0541\n",
      "[700]\ttraining's rmse: 0.965677\tvalid_1's rmse: 1.05093\n",
      "[800]\ttraining's rmse: 0.953332\tvalid_1's rmse: 1.04821\n",
      "[900]\ttraining's rmse: 0.941611\tvalid_1's rmse: 1.04669\n",
      "[1000]\ttraining's rmse: 0.930644\tvalid_1's rmse: 1.0454\n",
      "[1100]\ttraining's rmse: 0.920105\tvalid_1's rmse: 1.04442\n",
      "[1200]\ttraining's rmse: 0.909876\tvalid_1's rmse: 1.04401\n",
      "[1300]\ttraining's rmse: 0.90018\tvalid_1's rmse: 1.0433\n",
      "[1400]\ttraining's rmse: 0.891036\tvalid_1's rmse: 1.04291\n",
      "[1500]\ttraining's rmse: 0.881845\tvalid_1's rmse: 1.0431\n",
      "[1600]\ttraining's rmse: 0.872876\tvalid_1's rmse: 1.0424\n",
      "[1700]\ttraining's rmse: 0.864072\tvalid_1's rmse: 1.04215\n",
      "[1800]\ttraining's rmse: 0.85543\tvalid_1's rmse: 1.04216\n",
      "[1900]\ttraining's rmse: 0.847261\tvalid_1's rmse: 1.04175\n",
      "[2000]\ttraining's rmse: 0.83916\tvalid_1's rmse: 1.04232\n",
      "[2100]\ttraining's rmse: 0.831184\tvalid_1's rmse: 1.04187\n",
      "[2200]\ttraining's rmse: 0.823335\tvalid_1's rmse: 1.04171\n",
      "[2300]\ttraining's rmse: 0.815585\tvalid_1's rmse: 1.04224\n",
      "[2400]\ttraining's rmse: 0.808071\tvalid_1's rmse: 1.04221\n",
      "[2500]\ttraining's rmse: 0.800543\tvalid_1's rmse: 1.04263\n",
      "[2600]\ttraining's rmse: 0.793279\tvalid_1's rmse: 1.04278\n",
      "Early stopping, best iteration is:\n",
      "[2194]\ttraining's rmse: 0.823818\tvalid_1's rmse: 1.04161\n",
      "QWK: 0.4569743107796783, RMSE: 1.0416103021992942\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's rmse: 1.09302\tvalid_1's rmse: 1.13047\n",
      "[200]\ttraining's rmse: 1.05422\tvalid_1's rmse: 1.10304\n",
      "[300]\ttraining's rmse: 1.02737\tvalid_1's rmse: 1.08657\n",
      "[400]\ttraining's rmse: 1.00746\tvalid_1's rmse: 1.07718\n",
      "[500]\ttraining's rmse: 0.991227\tvalid_1's rmse: 1.0713\n",
      "[600]\ttraining's rmse: 0.976905\tvalid_1's rmse: 1.06704\n",
      "[700]\ttraining's rmse: 0.96354\tvalid_1's rmse: 1.0635\n",
      "[800]\ttraining's rmse: 0.951393\tvalid_1's rmse: 1.06113\n",
      "[900]\ttraining's rmse: 0.939934\tvalid_1's rmse: 1.05887\n",
      "[1000]\ttraining's rmse: 0.929229\tvalid_1's rmse: 1.05727\n",
      "[1100]\ttraining's rmse: 0.919085\tvalid_1's rmse: 1.05595\n",
      "[1200]\ttraining's rmse: 0.909089\tvalid_1's rmse: 1.0554\n",
      "[1300]\ttraining's rmse: 0.899678\tvalid_1's rmse: 1.05477\n",
      "[1400]\ttraining's rmse: 0.890585\tvalid_1's rmse: 1.0534\n",
      "[1500]\ttraining's rmse: 0.881529\tvalid_1's rmse: 1.05298\n",
      "[1600]\ttraining's rmse: 0.872688\tvalid_1's rmse: 1.05244\n",
      "[1700]\ttraining's rmse: 0.86403\tvalid_1's rmse: 1.05229\n",
      "[1800]\ttraining's rmse: 0.855514\tvalid_1's rmse: 1.05204\n",
      "[1900]\ttraining's rmse: 0.847357\tvalid_1's rmse: 1.05169\n",
      "[2000]\ttraining's rmse: 0.839524\tvalid_1's rmse: 1.05162\n",
      "[2100]\ttraining's rmse: 0.831699\tvalid_1's rmse: 1.05163\n",
      "[2200]\ttraining's rmse: 0.824061\tvalid_1's rmse: 1.05122\n",
      "[2300]\ttraining's rmse: 0.816525\tvalid_1's rmse: 1.05118\n",
      "[2400]\ttraining's rmse: 0.809056\tvalid_1's rmse: 1.05097\n",
      "[2500]\ttraining's rmse: 0.801549\tvalid_1's rmse: 1.05108\n",
      "[2600]\ttraining's rmse: 0.79425\tvalid_1's rmse: 1.05102\n",
      "[2700]\ttraining's rmse: 0.787116\tvalid_1's rmse: 1.05115\n",
      "[2800]\ttraining's rmse: 0.780031\tvalid_1's rmse: 1.0509\n",
      "[2900]\ttraining's rmse: 0.772846\tvalid_1's rmse: 1.05119\n",
      "[3000]\ttraining's rmse: 0.765957\tvalid_1's rmse: 1.051\n",
      "[3100]\ttraining's rmse: 0.759136\tvalid_1's rmse: 1.05141\n",
      "[3200]\ttraining's rmse: 0.752474\tvalid_1's rmse: 1.05136\n",
      "[3300]\ttraining's rmse: 0.745801\tvalid_1's rmse: 1.05194\n",
      "Early stopping, best iteration is:\n",
      "[2825]\ttraining's rmse: 0.778291\tvalid_1's rmse: 1.05082\n",
      "QWK: 0.4593353700046855, RMSE: 1.0508171064210816\n",
      "\n",
      "QWK CV: 0.4494770392018535 +/- 0.014198690137366143\n",
      "RMSE CV: 1.038750930709226 +/- 0.009470958500000667\n"
     ]
    }
   ],
   "source": [
    "# Using LightGBM regression\n",
    "\n",
    "params = {'objective': 'mse',\n",
    "          'boosting': 'gbdt',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves': 10,\n",
    "          'max_depth': 5,\n",
    "          'min_data_in_leaf': 60,\n",
    "          'learning_rate': 0.01,\n",
    "          'bagging_fraction': 0.5,\n",
    "          'bagging_freq': 1,\n",
    "          'feature_fraction': 0.3,\n",
    "          'feature_fraction_seed': 73,\n",
    "          'lambda_l1': 0,\n",
    "          'lambda_l2': 0.3,\n",
    "          'verbosity': -1,\n",
    "          'seed': seed}\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "def cross_validation(X_train, y_train,\n",
    "                     params, \n",
    "                     n_splits=5,\n",
    "                     early_stopping_rounds=500,\n",
    "                     verbose_eval=100,\n",
    "                     num_boost_round=10000,\n",
    "                     seed=seed):\n",
    "\n",
    "    gr_kfold_split = GroupKFold(n_splits=5).split(X_train, y_train,\n",
    "                                                  groups=train_df['RescuerID'])\n",
    "\n",
    "    oof_train = np.zeros((X_train.shape[0]))\n",
    "    oof_test = np.zeros((X_test.shape[0], n_splits))\n",
    "    qwks, rmses = [], []\n",
    "    importances = []\n",
    "    i = 0\n",
    "    for train_index, valid_index in gr_kfold_split:\n",
    "        X_tr = X_train.iloc[train_index, :]\n",
    "        y_tr = y_train[train_index].values\n",
    "        X_val = X_train.iloc[valid_index, :]\n",
    "        y_val = y_train[valid_index].values\n",
    "        \n",
    "        # Text features \n",
    "        X_tr_text = text_feature_extractor.fit_transform(X_tr[text_columns]).set_index(X_tr.index)\n",
    "        X_val_text = text_feature_extractor.transform(X_val[text_columns]).set_index(X_val.index)       \n",
    "        X_tr = pd.concat([X_tr.drop(columns=text_columns),\n",
    "                          X_tr_text], axis=1)\n",
    "        X_val = pd.concat([X_val.drop(columns=text_columns),\n",
    "                          X_val_text], axis=1) \n",
    "        \n",
    "        # LGB datasets\n",
    "        d_train = lgb.Dataset(X_tr, label=y_tr)\n",
    "        d_valid = lgb.Dataset(X_val, label=y_val)\n",
    "        valid_sets = [d_train, d_valid]\n",
    "\n",
    "        # Training\n",
    "        print('Fold {}/{}'.format(i + 1, n_splits))\n",
    "        model = lgb.train(params,\n",
    "                          train_set=d_train,\n",
    "                          num_boost_round=num_boost_round,\n",
    "                          valid_sets=valid_sets,\n",
    "                          verbose_eval=verbose_eval,\n",
    "                          early_stopping_rounds=early_stopping_rounds,\n",
    "                          categorical_feature=cat_feats)\n",
    "\n",
    "        # Predictions\n",
    "        tr_pred = model.predict(X_tr)\n",
    "        val_pred = model.predict(X_val)\n",
    "       \n",
    "        # Rounding\n",
    "        thresholds = get_thresholds_from_dist(y_tr, tr_pred)\n",
    "        val_pred_rounded = allocate_to_rate(val_pred, thresholds)\n",
    "        \n",
    "        # Evaluation\n",
    "        qwk_val = qwk(y_val, val_pred_rounded)\n",
    "        rmse_val = rmse(y_val, val_pred)\n",
    "        qwks.append(qwk_val)\n",
    "        rmses.append(rmse_val)\n",
    "\n",
    "        # Out-of-fold predictions\n",
    "        oof_train[valid_index] = val_pred\n",
    "        \n",
    "        # Test predictions\n",
    "        X_test_text = text_feature_extractor.transform(X_test[text_columns]).set_index(X_test.index)\n",
    "        X_test_val = pd.concat([X_test.drop(columns=text_columns),\n",
    "                                X_test_text], axis=1)\n",
    "        test_pred = model.predict(X_test_val)\n",
    "        oof_test[:, i] = test_pred\n",
    "            \n",
    "        importance = model.feature_importance('gain') \n",
    "        importances.append(pd.Series(dict(zip(X_tr.columns, importance))))\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        print('QWK: {}, RMSE: {}\\n'.format(qwk_val, rmse_val))\n",
    "    \n",
    "    return qwks, rmses, oof_train, oof_test, importances\n",
    "\n",
    "qwks, rmses, oof_train, oof_test, importances = cross_validation(X_train, y_train, params)\n",
    "\n",
    "print('QWK CV: {} +/- {}'.format(np.mean(qwks), np.std(qwks)))\n",
    "print('RMSE CV: {} +/- {}'.format(np.mean(rmses), np.std(rmses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6b1b57b07de839d94a8e9bf324be7777b382acf"
   },
   "source": [
    "<a id=\"5\"></a> \n",
    "## 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "63ef79b0d8494db67f997eaca420d39492294eb7"
   },
   "outputs": [],
   "source": [
    "def submit(oof_train, oof_test):\n",
    "    \"\"\"Generates submission from test OOF predictions.\"\"\"\n",
    "    preds = oof_test.mean(axis=1)\n",
    "    \n",
    "    thresholds = get_thresholds_from_dist(y_train, preds)\n",
    "    preds = allocate_to_rate(preds, thresholds)\n",
    "\n",
    "    preds = preds.astype(np.int32)\n",
    "    submission = pd.DataFrame({'PetID': test_df['PetID'].values, 'AdoptionSpeed': preds})\n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    return preds\n",
    "    \n",
    "preds = submit(oof_train, oof_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
